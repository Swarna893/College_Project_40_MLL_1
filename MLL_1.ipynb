{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9079fe5-cd8b-4511-9de8-b8d66b9ffbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe6effb-c7b5-4085-9059-af93c03adf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file\n",
    "df = pd.read_excel(r\"C:\\Users\\HP\\Project\\MLL_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0062633-3516-40f8-8a18-737f844cdf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>31307</th>\n",
       "      <th>31308_at</th>\n",
       "      <th>31309_r_at</th>\n",
       "      <th>31310_at</th>\n",
       "      <th>31311_at</th>\n",
       "      <th>31312_at</th>\n",
       "      <th>31313_at</th>\n",
       "      <th>31314_at</th>\n",
       "      <th>31315_at</th>\n",
       "      <th>...</th>\n",
       "      <th>100_g_at</th>\n",
       "      <th>101_at</th>\n",
       "      <th>102_at</th>\n",
       "      <th>103_at</th>\n",
       "      <th>104_at</th>\n",
       "      <th>105_at</th>\n",
       "      <th>106_at</th>\n",
       "      <th>107_at</th>\n",
       "      <th>108_g_at</th>\n",
       "      <th>109_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>-135.7</td>\n",
       "      <td>-100.1</td>\n",
       "      <td>-94.6</td>\n",
       "      <td>-230</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-50.4</td>\n",
       "      <td>-36.3</td>\n",
       "      <td>139.5</td>\n",
       "      <td>31.6</td>\n",
       "      <td>...</td>\n",
       "      <td>548.7</td>\n",
       "      <td>-225.2</td>\n",
       "      <td>242.5</td>\n",
       "      <td>101.7</td>\n",
       "      <td>473.1</td>\n",
       "      <td>-59.9</td>\n",
       "      <td>217.9</td>\n",
       "      <td>275.6</td>\n",
       "      <td>-461.6</td>\n",
       "      <td>1115.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALL</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-145</td>\n",
       "      <td>491.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>-175.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>2481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALL</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>-130.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-51</td>\n",
       "      <td>236.0</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>-304.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>-308.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALL</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-124.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-139</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-411.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>798.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-190.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-353.0</td>\n",
       "      <td>1603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALL</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-112</td>\n",
       "      <td>452.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>730.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>-780.0</td>\n",
       "      <td>1103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AML</td>\n",
       "      <td>-324.0</td>\n",
       "      <td>-168.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>312</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-404.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>-422.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>-564.0</td>\n",
       "      <td>-1736.0</td>\n",
       "      <td>346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>AML</td>\n",
       "      <td>-148.0</td>\n",
       "      <td>-104.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>72</td>\n",
       "      <td>465.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-895.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2913.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-757.0</td>\n",
       "      <td>825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>AML</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>377</td>\n",
       "      <td>686.0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-123.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>-230.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>-2015.0</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>AML</td>\n",
       "      <td>-359.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>120</td>\n",
       "      <td>564.0</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-584.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-2038.0</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>AML</td>\n",
       "      <td>-251.0</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>129</td>\n",
       "      <td>540.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-781.0</td>\n",
       "      <td>-441.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>-625.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>-313.0</td>\n",
       "      <td>-1770.0</td>\n",
       "      <td>791.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 12534 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  31307  31308_at  31309_r_at  31310_at  31311_at  31312_at  31313_at  \\\n",
       "0    ALL -135.7    -100.1       -94.6      -230       0.6     -50.4     -36.3   \n",
       "1    ALL  -80.0     -23.0        -6.0      -145     491.0     290.0    -235.0   \n",
       "2    ALL  -91.0    -130.0       -27.0       -51     236.0    -163.0    -304.0   \n",
       "3    ALL -144.0    -124.0       -26.0      -139     -88.0      34.0    -411.0   \n",
       "4    ALL  -89.0     -25.0       -64.0      -112     452.0     183.0     107.0   \n",
       "..   ...    ...       ...         ...       ...       ...       ...       ...   \n",
       "67   AML -324.0    -168.0       -49.0       312    1059.0     -24.0    -404.0   \n",
       "68   AML -148.0    -104.0        29.0        72     465.0     162.0    -895.0   \n",
       "69   AML -230.0     -66.0       -69.0       377     686.0     -44.0    -123.0   \n",
       "70   AML -359.0     -52.0      -147.0       120     564.0     -52.0    -584.0   \n",
       "71   AML -251.0    -225.0       -64.0       129     540.0     181.0    -781.0   \n",
       "\n",
       "    31314_at  31315_at  ...  100_g_at  101_at  102_at  103_at  104_at  105_at  \\\n",
       "0      139.5      31.6  ...     548.7  -225.2   242.5   101.7   473.1   -59.9   \n",
       "1       41.0    4602.0  ...    1464.0  -175.0   143.0    96.0   301.0   -50.0   \n",
       "2      -35.0     498.0  ...     339.0  -308.0   184.0   -32.0   350.0   -11.0   \n",
       "3      118.0    -239.0  ...     798.0   731.0   106.0  -330.0   -36.0  -190.0   \n",
       "4      233.0      38.0  ...     730.0   182.0   426.0   155.0   607.0    50.0   \n",
       "..       ...       ...  ...       ...     ...     ...     ...     ...     ...   \n",
       "67      12.0     101.0  ...    1808.0  -422.0   528.0   220.0   643.0   187.0   \n",
       "68      33.0    1736.0  ...    2913.0   128.0    94.0    66.0   556.0    63.0   \n",
       "69       7.0     310.0  ...    2555.0  -230.0   257.0    71.0   581.0    64.0   \n",
       "70      64.0    2528.0  ...    1982.0  -236.0    88.0    94.0   143.0   232.0   \n",
       "71    -441.0     150.0  ...    2495.0  -625.0   139.0     7.0   718.0   230.0   \n",
       "\n",
       "    106_at  107_at  108_g_at  109_at  \n",
       "0    217.9   275.6    -461.6  1115.5  \n",
       "1    242.0   222.0    -330.0  2481.0  \n",
       "2    837.0   174.0     -99.0   376.0  \n",
       "3    999.0   255.0    -353.0  1603.0  \n",
       "4    249.0  1635.0    -780.0  1103.0  \n",
       "..     ...     ...       ...     ...  \n",
       "67   407.0  -564.0   -1736.0   346.0  \n",
       "68   200.0   120.0    -757.0   825.0  \n",
       "69    35.0   829.0   -2015.0   385.0  \n",
       "70   434.0   -87.0   -2038.0  1228.0  \n",
       "71   743.0  -313.0   -1770.0   791.0  \n",
       "\n",
       "[72 rows x 12534 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79423880-0690-48ac-85bb-2e81624ae399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72 entries, 0 to 71\n",
      "Columns: 12534 entries, class to 109_at\n",
      "dtypes: float64(11224), int64(1309), object(1)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c67a0b5-aeb3-43e9-86bf-47d0ccf8efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88caf4da-9b6a-4201-9097-e9b0c16efd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features:\n",
      "Index(['41589_at', '34959_at', '40849_s_at', '34859_at', '32685_at',\n",
      "       '33489_at', '32293_at', '33439_at', '35621_at', '36669_at', '32254_at',\n",
      "       '34605_at', '35855_s_at', '39651_at', '33180_at', '39706_at',\n",
      "       '37289_at', '33298_at', '37805_at', '38107_at'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1️ Load & clean dataset\n",
    "# -----------------------------\n",
    "df = pd.read_excel(r\"C:\\Users\\HP\\Project\\MLL_1.xlsx\", sheet_name='Sheet1')\n",
    "df_clean = df.iloc[2:].reset_index(drop=True)  # remove first 2 rows\n",
    "\n",
    "# Ensure all column names are strings to avoid KeyError later\n",
    "df_clean.columns = df_clean.columns.astype(str)\n",
    "\n",
    "# -----------------------------\n",
    "# 2️ Separate features and target\n",
    "# -----------------------------\n",
    "X = df_clean.drop(columns=['class']).astype(float)\n",
    "X.columns = X.columns.astype(str)  # ensure column names are strings\n",
    "y = df_clean['class']\n",
    "\n",
    "# -----------------------------\n",
    "# 3️ Scale all features for autoencoder\n",
    "# -----------------------------\n",
    "scaler_all = StandardScaler()\n",
    "X_scaled_all = scaler_all.fit_transform(X)\n",
    "\n",
    "# -----------------------------\n",
    "# 4️ Folded Autoencoder for feature selection\n",
    "# -----------------------------\n",
    "hidden_dim = 5\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(hidden_dim,),\n",
    "                           max_iter=100,\n",
    "                           random_state=0)\n",
    "autoencoder.fit(X_scaled_all, X_scaled_all)\n",
    "\n",
    "# -----------------------------\n",
    "# 5️ Compute feature importance\n",
    "# -----------------------------\n",
    "coefs = autoencoder.coefs_[0]  # weights from input layer to hidden layer\n",
    "feature_importance = np.sum(np.abs(coefs), axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# 6️ Select top 20 features\n",
    "# -----------------------------\n",
    "k = 20\n",
    "top_features_idx = np.argsort(feature_importance)[::-1][:k]\n",
    "top_features = X.columns[top_features_idx]\n",
    "\n",
    "print(\"Top 20 features:\")\n",
    "print(top_features)\n",
    "\n",
    "# -----------------------------\n",
    "# 7️ Shuffle & normalize only top 20 features\n",
    "# -----------------------------\n",
    "df_selected = df_clean[top_features.tolist() + ['class']]\n",
    "df_shuffled = df_selected.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_top = df_shuffled[top_features].astype(float)\n",
    "y_top = df_shuffled['class']\n",
    "\n",
    "scaler_top = StandardScaler()\n",
    "X_top_scaled = scaler_top.fit_transform(X_top)\n",
    "\n",
    "# -----------------------------\n",
    "# 8️ Optional: combine scaled features with target\n",
    "# -----------------------------\n",
    "df_final = pd.DataFrame(X_top_scaled, columns=top_features)\n",
    "df_final['class'] = y_top.values\n",
    "\n",
    "# -----------------------------\n",
    "# Now ready for modeling\n",
    "# X_top_scaled -> normalized top 20 features\n",
    "# y_top -> target labels\n",
    "# df_final -> shuffled + normalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a262dfd7-6346-4acb-9362-5fd6bc02ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>41589_at</th>\n",
       "      <th>34959_at</th>\n",
       "      <th>40849_s_at</th>\n",
       "      <th>34859_at</th>\n",
       "      <th>32685_at</th>\n",
       "      <th>33489_at</th>\n",
       "      <th>32293_at</th>\n",
       "      <th>33439_at</th>\n",
       "      <th>35621_at</th>\n",
       "      <th>36669_at</th>\n",
       "      <th>...</th>\n",
       "      <th>34605_at</th>\n",
       "      <th>35855_s_at</th>\n",
       "      <th>39651_at</th>\n",
       "      <th>33180_at</th>\n",
       "      <th>39706_at</th>\n",
       "      <th>37289_at</th>\n",
       "      <th>33298_at</th>\n",
       "      <th>37805_at</th>\n",
       "      <th>38107_at</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.638247</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>-0.332653</td>\n",
       "      <td>-0.354327</td>\n",
       "      <td>-0.722262</td>\n",
       "      <td>0.306102</td>\n",
       "      <td>0.173950</td>\n",
       "      <td>0.641421</td>\n",
       "      <td>0.135596</td>\n",
       "      <td>-0.047622</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084377</td>\n",
       "      <td>0.150879</td>\n",
       "      <td>-0.469394</td>\n",
       "      <td>-0.794542</td>\n",
       "      <td>-0.305796</td>\n",
       "      <td>0.696188</td>\n",
       "      <td>0.122672</td>\n",
       "      <td>1.202397</td>\n",
       "      <td>-0.289912</td>\n",
       "      <td>MLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.438738</td>\n",
       "      <td>-0.044519</td>\n",
       "      <td>-0.981880</td>\n",
       "      <td>-1.399806</td>\n",
       "      <td>-0.492985</td>\n",
       "      <td>-0.369252</td>\n",
       "      <td>-0.046029</td>\n",
       "      <td>-0.116986</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553105</td>\n",
       "      <td>-0.220533</td>\n",
       "      <td>-0.359194</td>\n",
       "      <td>-0.376628</td>\n",
       "      <td>-0.789986</td>\n",
       "      <td>0.569996</td>\n",
       "      <td>-0.145673</td>\n",
       "      <td>1.331436</td>\n",
       "      <td>-0.952776</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.216958</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-1.571125</td>\n",
       "      <td>-0.721441</td>\n",
       "      <td>0.340241</td>\n",
       "      <td>-1.370002</td>\n",
       "      <td>0.018670</td>\n",
       "      <td>-0.653136</td>\n",
       "      <td>1.348651</td>\n",
       "      <td>-0.492371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.441514</td>\n",
       "      <td>0.100157</td>\n",
       "      <td>-0.351180</td>\n",
       "      <td>-0.143560</td>\n",
       "      <td>0.379470</td>\n",
       "      <td>0.707660</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.049649</td>\n",
       "      <td>-1.202790</td>\n",
       "      <td>AML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599948</td>\n",
       "      <td>-0.236669</td>\n",
       "      <td>-0.590227</td>\n",
       "      <td>1.539773</td>\n",
       "      <td>2.431694</td>\n",
       "      <td>-0.811301</td>\n",
       "      <td>-0.078379</td>\n",
       "      <td>-0.721064</td>\n",
       "      <td>0.109725</td>\n",
       "      <td>-1.079349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589494</td>\n",
       "      <td>-0.254893</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>-0.776861</td>\n",
       "      <td>0.911919</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.142798</td>\n",
       "      <td>1.030345</td>\n",
       "      <td>0.047277</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.224954</td>\n",
       "      <td>-0.128366</td>\n",
       "      <td>0.762918</td>\n",
       "      <td>1.245815</td>\n",
       "      <td>-1.180816</td>\n",
       "      <td>-0.442926</td>\n",
       "      <td>0.335699</td>\n",
       "      <td>1.616412</td>\n",
       "      <td>0.696131</td>\n",
       "      <td>2.009623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720492</td>\n",
       "      <td>0.145970</td>\n",
       "      <td>-0.868117</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>-0.622691</td>\n",
       "      <td>-0.313350</td>\n",
       "      <td>0.686197</td>\n",
       "      <td>0.772267</td>\n",
       "      <td>-0.444526</td>\n",
       "      <td>AML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.464428</td>\n",
       "      <td>1.960833</td>\n",
       "      <td>-1.059505</td>\n",
       "      <td>0.333349</td>\n",
       "      <td>-0.146274</td>\n",
       "      <td>-0.418368</td>\n",
       "      <td>0.025140</td>\n",
       "      <td>2.589366</td>\n",
       "      <td>-0.094367</td>\n",
       "      <td>2.154298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.296498</td>\n",
       "      <td>0.181787</td>\n",
       "      <td>0.333826</td>\n",
       "      <td>-0.485960</td>\n",
       "      <td>0.535580</td>\n",
       "      <td>0.129381</td>\n",
       "      <td>0.428164</td>\n",
       "      <td>0.585135</td>\n",
       "      <td>MLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.228742</td>\n",
       "      <td>0.220998</td>\n",
       "      <td>0.216014</td>\n",
       "      <td>0.030080</td>\n",
       "      <td>0.983335</td>\n",
       "      <td>-1.093721</td>\n",
       "      <td>0.031610</td>\n",
       "      <td>-0.762374</td>\n",
       "      <td>1.549869</td>\n",
       "      <td>-0.811446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.975510</td>\n",
       "      <td>0.802913</td>\n",
       "      <td>-0.961708</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>-0.255990</td>\n",
       "      <td>0.632528</td>\n",
       "      <td>0.350740</td>\n",
       "      <td>0.154191</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.145410</td>\n",
       "      <td>0.538920</td>\n",
       "      <td>-1.902795</td>\n",
       "      <td>0.393204</td>\n",
       "      <td>-0.789368</td>\n",
       "      <td>-0.295577</td>\n",
       "      <td>-0.278948</td>\n",
       "      <td>-0.337206</td>\n",
       "      <td>-1.189566</td>\n",
       "      <td>-0.130777</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438558</td>\n",
       "      <td>1.345286</td>\n",
       "      <td>-1.795799</td>\n",
       "      <td>1.873680</td>\n",
       "      <td>-0.162630</td>\n",
       "      <td>1.051821</td>\n",
       "      <td>0.437978</td>\n",
       "      <td>-0.070787</td>\n",
       "      <td>1.364781</td>\n",
       "      <td>AML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.177379</td>\n",
       "      <td>-0.631451</td>\n",
       "      <td>-0.170347</td>\n",
       "      <td>-0.024455</td>\n",
       "      <td>0.155701</td>\n",
       "      <td>-1.056884</td>\n",
       "      <td>0.154540</td>\n",
       "      <td>0.788768</td>\n",
       "      <td>0.244829</td>\n",
       "      <td>-0.362558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405125</td>\n",
       "      <td>0.685907</td>\n",
       "      <td>0.187798</td>\n",
       "      <td>2.204797</td>\n",
       "      <td>-0.175499</td>\n",
       "      <td>-0.278934</td>\n",
       "      <td>-1.185511</td>\n",
       "      <td>0.032444</td>\n",
       "      <td>0.249590</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.295660</td>\n",
       "      <td>-0.673375</td>\n",
       "      <td>-0.823102</td>\n",
       "      <td>1.239164</td>\n",
       "      <td>-1.398909</td>\n",
       "      <td>2.792630</td>\n",
       "      <td>-0.168959</td>\n",
       "      <td>-0.770083</td>\n",
       "      <td>-0.286961</td>\n",
       "      <td>-1.044920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308089</td>\n",
       "      <td>1.402552</td>\n",
       "      <td>-0.104733</td>\n",
       "      <td>-0.710960</td>\n",
       "      <td>-0.675775</td>\n",
       "      <td>1.935167</td>\n",
       "      <td>-0.085295</td>\n",
       "      <td>-0.741790</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>AML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    41589_at  34959_at  40849_s_at  34859_at  32685_at  33489_at  32293_at  \\\n",
       "0   0.638247  0.081252   -0.332653 -0.354327 -0.722262  0.306102  0.173950   \n",
       "1  -1.438738 -0.044519   -0.981880 -1.399806 -0.492985 -0.369252 -0.046029   \n",
       "2   0.216958  0.032341   -1.571125 -0.721441  0.340241 -1.370002  0.018670   \n",
       "3   0.599948 -0.236669   -0.590227  1.539773  2.431694 -0.811301 -0.078379   \n",
       "4  -0.224954 -0.128366    0.762918  1.245815 -1.180816 -0.442926  0.335699   \n",
       "..       ...       ...         ...       ...       ...       ...       ...   \n",
       "65  0.464428  1.960833   -1.059505  0.333349 -0.146274 -0.418368  0.025140   \n",
       "66  0.228742  0.220998    0.216014  0.030080  0.983335 -1.093721  0.031610   \n",
       "67 -0.145410  0.538920   -1.902795  0.393204 -0.789368 -0.295577 -0.278948   \n",
       "68  1.177379 -0.631451   -0.170347 -0.024455  0.155701 -1.056884  0.154540   \n",
       "69 -0.295660 -0.673375   -0.823102  1.239164 -1.398909  2.792630 -0.168959   \n",
       "\n",
       "    33439_at  35621_at  36669_at  ...  34605_at  35855_s_at  39651_at  \\\n",
       "0   0.641421  0.135596 -0.047622  ... -1.084377    0.150879 -0.469394   \n",
       "1  -0.116986  0.003367 -0.009619  ...  0.553105   -0.220533 -0.359194   \n",
       "2  -0.653136  1.348651 -0.492371  ... -0.441514    0.100157 -0.351180   \n",
       "3  -0.721064  0.109725 -1.079349  ...  0.589494   -0.254893  0.021496   \n",
       "4   1.616412  0.696131  2.009623  ... -0.720492    0.145970 -0.868117   \n",
       "..       ...       ...       ...  ...       ...         ...       ...   \n",
       "65  2.589366 -0.094367  2.154298  ...  0.674400    0.296498  0.181787   \n",
       "66 -0.762374  1.549869 -0.811446  ...  0.019407    0.975510  0.802913   \n",
       "67 -0.337206 -1.189566 -0.130777  ...  1.438558    1.345286 -1.795799   \n",
       "68  0.788768  0.244829 -0.362558  ... -0.405125    0.685907  0.187798   \n",
       "69 -0.770083 -0.286961 -1.044920  ... -0.308089    1.402552 -0.104733   \n",
       "\n",
       "    33180_at  39706_at  37289_at  33298_at  37805_at  38107_at  class  \n",
       "0  -0.794542 -0.305796  0.696188  0.122672  1.202397 -0.289912    MLL  \n",
       "1  -0.376628 -0.789986  0.569996 -0.145673  1.331436 -0.952776    ALL  \n",
       "2  -0.143560  0.379470  0.707660  0.149507  0.049649 -1.202790    AML  \n",
       "3  -0.776861  0.911919  0.179947  0.142798  1.030345  0.047277    ALL  \n",
       "4   0.097544 -0.622691 -0.313350  0.686197  0.772267 -0.444526    AML  \n",
       "..       ...       ...       ...       ...       ...       ...    ...  \n",
       "65  0.333826 -0.485960  0.535580  0.129381  0.428164  0.585135    MLL  \n",
       "66 -0.961708  0.046489 -0.255990  0.632528  0.350740  0.154191    ALL  \n",
       "67  1.873680 -0.162630  1.051821  0.437978 -0.070787  1.364781    AML  \n",
       "68  2.204797 -0.175499 -0.278934 -1.185511  0.032444  0.249590    ALL  \n",
       "69 -0.710960 -0.675775  1.935167 -0.085295 -0.741790  0.025894    AML  \n",
       "\n",
       "[70 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be767e4-7b4c-4fd6-9579-adb1936e35c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL' 'MLL' 'AML']\n"
     ]
    }
   ],
   "source": [
    "# Display distinct values of a column, e.g. 'City'\n",
    "unique_values = df['class'].unique()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7be204-9f21-49e2-b16b-7c4a7d80670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty cells in each column:\n",
      "class         0\n",
      "31307         0\n",
      "31308_at      0\n",
      "31309_r_at    0\n",
      "31310_at      0\n",
      "             ..\n",
      "105_at        0\n",
      "106_at        0\n",
      "107_at        0\n",
      "108_g_at      0\n",
      "109_at        0\n",
      "Length: 12534, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count empty (NaN) cells in each column\n",
    "empty_counts = df.isna().sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of empty cells in each column:\")\n",
    "print(empty_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c880edd-6641-484b-ae22-088e5d9474a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bd3d8-6669-440e-8bdc-e8d0d5886a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1️⃣ Train-test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_top_scaled, y_top, test_size=0.2, random_state=42, stratify=y_top\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Define Random Forest model\n",
    "# -----------------------------\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,       # number of trees\n",
    "    max_depth=None,         # grow trees fully\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Train the model\n",
    "# -----------------------------\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Make predictions\n",
    "# -----------------------------\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Evaluate the model\n",
    "# -----------------------------\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6cef05-f054-4d0c-81a8-0c20ba579f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion Matrix\n",
    "# -----------------------------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# -----------------------------\n",
    "# Precision and Recall (per class)\n",
    "# -----------------------------\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "print(\"\\nPrecision per class:\", precision)\n",
    "print(\"Recall (Sensitivity) per class:\", recall)\n",
    "\n",
    "# -----------------------------\n",
    "# Specificity and Negative Predictive Value (NPV)\n",
    "# -----------------------------\n",
    "specificity = []\n",
    "npv = []\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    spec = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    npv_val = TN / (TN + FN) if (TN + FN) != 0 else 0\n",
    "    \n",
    "    specificity.append(spec)\n",
    "    npv.append(npv_val)\n",
    "\n",
    "print(\"Specificity per class:\", specificity)\n",
    "print(\"Negative Predictive Value (NPV) per class:\", npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda27a4-31ef-458e-b339-dbc08bd1edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfac9e-175e-4906-8fb8-ed43e1d5809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1️⃣ Define RandomForest and parameter grid\n",
    "# -----------------------------\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Grid Search with 5-fold cross-validation\n",
    "# -----------------------------\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1,  # use all cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Evaluate on test set\n",
    "# -----------------------------\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred_best)\n",
    "print(\"\\nTest Accuracy with Best RF:\", test_acc)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33906336-c54c-4dbc-8d1d-61be408fc81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
